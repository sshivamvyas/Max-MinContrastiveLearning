# Max-MinContrastiveLearning
MMCL re‑thinks unsupervised representation learning by replacing the “random pile of negatives” used in standard contrastive methods with a support‑vector‑driven selection strategy inspired by SVMs. Fewer—but far more informative—negatives translate into stronger margins, better features, and noticeably quicker training.
